{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10562069,"sourceType":"datasetVersion","datasetId":6531643},{"sourceId":10730648,"sourceType":"datasetVersion","datasetId":6525542},{"sourceId":13578880,"sourceType":"datasetVersion","datasetId":8558647},{"sourceId":13580215,"sourceType":"datasetVersion","datasetId":8627715},{"sourceId":352617,"sourceType":"modelInstanceVersion","modelInstanceId":294154,"modelId":314773}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# --- 1. Define paths to BOTH datasets ---\n\n# Path to the CSVs (train_sent_emo.csv, etc.)\nmetadata_path = '/kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw' \n\n# Path to the audio (audio_train/, audio_dev/, etc.)\naudio_root_path = '/kaggle/input/meld-audio'\n\n# --- 2. Load data from the CSV files ---\n\nall_df = []\ntotal_rows_loaded = 0\n\nprint(f\"Loading metadata from CSVs in: {metadata_path}\")\n\nfor split in ['train', 'dev', 'test']:\n    \n    # --- MODIFICATION ---\n    # Handle the special path for the 'train' file\n    if split == 'train':\n        csv_file_path = os.path.join(metadata_path, 'train', f\"{split}_sent_emo.csv\")\n    else:\n        # 'dev' and 'test' are in the base metadata path\n        csv_file_path = os.path.join(metadata_path, f\"{split}_sent_emo.csv\")\n    # --- END MODIFICATION ---\n\n    print(f\"Attempting to load: {csv_file_path}\")\n    \n    try:\n        # Load the CSV file\n        df_split = pd.read_csv(csv_file_path)\n        \n        # Add a 'split' column (to find audio_train, audio_dev, etc.)\n        df_split['split'] = split\n        \n        all_df.append(df_split)\n        # Print the filename, not the full path, for clarity\n        print(f\"✓ Loaded {len(df_split)} rows from {split}_sent_emo.csv\")\n        total_rows_loaded += len(df_split)\n        \n    except FileNotFoundError:\n        print(f\"Error: Could not find file {csv_file_path}. Please double-check path.\")\n\n# --- 3. Combine, Filter, and Save ---\n\nif not all_df:\n    print(\"\\nError: No CSV data was loaded. Cannot proceed.\")\nelse:\n    # Combine all DataFrames (train, dev, test) into one\n    df = pd.concat(all_df, ignore_index=True)\n    print(f\"\\nTotal rows loaded from all CSVs: {len(df)}\")\n\n    # Check if we have the necessary columns\n    if 'Dialogue_ID' not in df.columns or 'Utterance_ID' not in df.columns:\n        print(\"\\nError: The loaded CSVs are missing 'Dialogue_ID' or 'Utterance_ID'.\")\n        print(f\"Available columns are: {list(df.columns)}\")\n    else:\n        # Add the full audio path\n        df['audio_path'] = df.apply(\n            lambda row: os.path.join(\n                audio_root_path,\n                f\"audio_{row['split']}\",\n                f\"dia{int(row['Dialogue_ID'])}_utt{int(row['Utterance_ID'])}.wav\"\n            ),\n            axis=1\n        )\n\n        # Filter for existing .wav files\n        print(f\"Checking for .wav files in: {audio_root_path} (this may take a minute)...\")\n        df = df[df['audio_path'].apply(os.path.exists)]\n        print(\"File check complete.\")\n\n        # Save the final, complete dataset\n        df.to_csv('MELD_complete_dataset.csv', index=False)\n\n        print(f\"\\n✓ CSV created: {len(df)} samples\")\n        if len(df) == 0:\n            print(\"\\nWarning: 0 audio samples were found.\")\n            print(f\"This means the file names in the CSVs do not match the .wav files.\")\n        else:\n            print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T18:37:34.525245Z","iopub.execute_input":"2025-10-23T18:37:34.525870Z","iopub.status.idle":"2025-10-23T18:37:52.452264Z","shell.execute_reply.started":"2025-10-23T18:37:34.525844Z","shell.execute_reply":"2025-10-23T18:37:52.451122Z"}},"outputs":[{"name":"stdout","text":"Loading metadata from CSVs in: /kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw\nAttempting to load: /kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw/train/train_sent_emo.csv\n✓ Loaded 9989 rows from train_sent_emo.csv\nAttempting to load: /kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw/dev_sent_emo.csv\n✓ Loaded 1109 rows from dev_sent_emo.csv\nAttempting to load: /kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw/test_sent_emo.csv\n✓ Loaded 2610 rows from test_sent_emo.csv\n\nTotal rows loaded from all CSVs: 13708\nChecking for .wav files in: /kaggle/input/meld-audio (this may take a minute)...\nFile check complete.\n\n✓ CSV created: 13706 samples\n   Sr No.                                          Utterance          Speaker  \\\n0       1  also I was the point person on my companys tr...         Chandler   \n1       2                   You mustve had your hands full.  The Interviewer   \n2       3                            That I did. That I did.         Chandler   \n3       4      So lets talk a little bit about your duties.  The Interviewer   \n4       5                             My duties?  All right.         Chandler   \n\n    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n0   neutral   neutral            0             0       8       21   \n1   neutral   neutral            0             1       8       21   \n2   neutral   neutral            0             2       8       21   \n3   neutral   neutral            0             3       8       21   \n4  surprise  positive            0             4       8       21   \n\n      StartTime       EndTime  split  \\\n0  00:16:16,059  00:16:21,731  train   \n1  00:16:21,940  00:16:23,442  train   \n2  00:16:23,442  00:16:26,389  train   \n3  00:16:26,820  00:16:29,572  train   \n4  00:16:34,452  00:16:40,917  train   \n\n                                          audio_path  \n0  /kaggle/input/meld-audio/audio_train/dia0_utt0...  \n1  /kaggle/input/meld-audio/audio_train/dia0_utt1...  \n2  /kaggle/input/meld-audio/audio_train/dia0_utt2...  \n3  /kaggle/input/meld-audio/audio_train/dia0_utt3...  \n4  /kaggle/input/meld-audio/audio_train/dia0_utt4...  \n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!pip install transformers huggingface_hub --upgrade -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T19:29:12.925440Z","iopub.execute_input":"2025-10-23T19:29:12.926257Z","iopub.status.idle":"2025-10-23T19:29:28.364541Z","shell.execute_reply.started":"2025-10-23T19:29:12.926225Z","shell.execute_reply":"2025-10-23T19:29:28.363747Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m908.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport torch\n# --- MODIFICATION ---\n# Using Auto* classes is the most robust way.\n# They will read the config.json and load the correct classes (BertTokenizer, BertModel) automatically.\nfrom transformers import AutoTokenizer, AutoModel\n# --- END MODIFICATION ---\nfrom tqdm.notebook import tqdm  # For a nice progress bar\nimport os # Import os to check the path\n\n# --- 1. Configuration ---\nMODEL_NAME = \"/kaggle/input/distilbertdistilbert-base-uncased/transformers/default/1\" \nCSV_PATH = \"/kaggle/input/meld-data/MELD_complete_dataset.csv\"\nOUTPUT_FILE = \"meld-text-embeddings.npy\"\nBATCH_SIZE = 128 # You can make this smaller if you get memory errors, e.g., 64 or 32\n\n# --- 2. Text Cleaning Function ---\ndef clean_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    text = re.sub(r\"[\\x91\\x92\\x93\\x94ââ]\", \"'\", text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# --- 3. Mean Pooling Function ---\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\n# --- 4. Main Embedding Generation ---\n\nprint(\"Script started.\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nif not os.path.exists(MODEL_NAME):\n    print(f\"CRITICAL ERROR: MODEL DATASET NOT FOUND at {MODEL_NAME}\")\n    raise FileNotFoundError(\"Model dataset not added to notebook.\")\nelse:\n    print(f\"Found local model files at: {MODEL_NAME}. Proceeding...\")\n\ntry:\n    df = pd.read_csv(CSV_PATH)\n    print(f\"Successfully loaded CSV with {len(df)} rows.\")\nexcept FileNotFoundError:\n    print(f\"Error: Could not find file at {CSV_PATH}\")\n    raise\n\nprint(\"Cleaning text...\")\ndf['cleaned_utterance'] = df['Utterance'].apply(clean_text)\ntexts = df['cleaned_utterance'].tolist()\n\n# --- MODIFICATION ---\nprint(f\"Loading tokenizer from local path...\")\n# Load the tokenizer using AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n\nprint(f\"Loading model from local path...\")\n# Load the model using AutoModel\nmodel = AutoModel.from_pretrained(MODEL_NAME)\n# --- END MODIFICATION ---\n\nmodel.to(device)\nmodel.eval()\n\nall_embeddings = []\nprint(f\"Starting embedding generation in batches of {BATCH_SIZE}...\")\n\nfor i in tqdm(range(0, len(texts), BATCH_SIZE)):\n    batch_texts = texts[i:i + BATCH_SIZE]\n    \n    inputs = tokenizer(\n        batch_texts,\n        padding=True,\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n    \n    inputs = {key: val.to(device) for key, val in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    batch_embeddings = mean_pooling(outputs, inputs['attention_mask'])\n    all_embeddings.append(batch_embeddings.cpu().numpy())\n\nprint(\"Embedding generation complete. Concatenating results...\")\nembeddings = np.concatenate(all_embeddings, axis=0)\nnp.save(OUTPUT_FILE, embeddings)\n\nprint(\"-\" * 30)\nprint(f\"✓ Success! Embeddings saved to {OUTPUT_FILE}\")\nprint(f\"Embedding shape: {embeddings.shape}\")\nprint(f\"\\nYour '{OUTPUT_FILE}' file is now in the output directory '/kaggle/working/'.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T19:48:53.007635Z","iopub.execute_input":"2025-10-23T19:48:53.007929Z","iopub.status.idle":"2025-10-23T19:49:53.289859Z","shell.execute_reply.started":"2025-10-23T19:48:53.007907Z","shell.execute_reply":"2025-10-23T19:49:53.289195Z"}},"outputs":[{"name":"stdout","text":"Script started.\nUsing device: cuda\nFound local model files at: /kaggle/input/distilbertdistilbert-base-uncased/transformers/default/1. Proceeding...\nSuccessfully loaded CSV with 13706 rows.\nCleaning text...\nLoading tokenizer from local path...\nLoading model from local path...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-10-23 19:49:11.724895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761248951.900504      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761248951.951854      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Starting embedding generation in batches of 128...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0764874ef16d466896944b4b0e9aa463"}},"metadata":{}},{"name":"stdout","text":"Embedding generation complete. Concatenating results...\n------------------------------\n✓ Success! Embeddings saved to meld-text-embeddings.npy\nEmbedding shape: (13706, 768)\n\nYour 'meld-text-embeddings.npy' file is now in the output directory '/kaggle/working/'.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install librosa -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:05.266808Z","iopub.execute_input":"2025-10-23T20:07:05.267357Z","iopub.status.idle":"2025-10-23T20:07:09.293957Z","shell.execute_reply.started":"2025-10-23T20:07:05.267331Z","shell.execute_reply":"2025-10-23T20:07:09.292984Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport librosa  # Audio loading library\nfrom transformers import AutoProcessor, Wav2Vec2Model\nfrom tqdm.notebook import tqdm\nimport os\nimport warnings\n\n# --- 1. Configuration ---\nwarnings.filterwarnings('ignore', category=UserWarning, module='librosa')\n\nMODEL_PATH = \"/kaggle/input/meld-data/wave2vec-model\" \nCSV_PATH = \"/kaggle/input/meld-data/MELD_complete_dataset.csv\"\nOUTPUT_FILE = \"meld-audio-embeddings.npy\"\nTARGET_SAMPLE_RATE = 16000\nBATCH_SIZE = 32\n\n# --- 2. Mean Pooling Function ---\n# --- REMOVED --- (No longer needed with simpler pooling)\n\n# --- 3. Audio Loading Function ---\ndef load_and_resample_audio(file_path):\n    try:\n        speech, sr = librosa.load(file_path, sr=TARGET_SAMPLE_RATE, mono=True)\n        # Add a check for empty audio files after loading\n        if speech.size == 0:\n            print(f\"Warning: Loaded empty audio from {file_path}. Returning zeros.\")\n            # Return zeros matching expected feature size (use model config later if needed)\n            # For now, let's return zeros of a typical length, processor will pad\n            return np.zeros(TARGET_SAMPLE_RATE) # e.g., 1 second of zeros\n        return speech\n    except Exception as e:\n        print(f\"Error loading {file_path}: {e}\")\n        return np.zeros(TARGET_SAMPLE_RATE)\n\n# --- 4. Main Embedding Generation ---\n\nprint(\"Script started.\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Check model path\nif not os.path.exists(MODEL_PATH):\n    print(f\"CRITICAL ERROR: MODEL FOLDER NOT FOUND at {MODEL_PATH}\")\n    raise FileNotFoundError(\"Model folder not found in dataset.\")\nelse:\n    config_path = os.path.join(MODEL_PATH, 'config.json')\n    if not os.path.exists(config_path):\n         print(f\"CRITICAL ERROR: config.json not found in {MODEL_PATH}\")\n         raise FileNotFoundError(\"config.json missing\")\n    print(f\"Found local model files at: {MODEL_PATH}. Proceeding...\")\n\n# Load CSV\ntry:\n    df = pd.read_csv(CSV_PATH)\n    print(f\"Successfully loaded CSV with {len(df)} rows.\")\nexcept FileNotFoundError:\n    print(f\"Error: Could not find file at {CSV_PATH}\")\n    raise\n\naudio_paths = df['audio_path'].tolist()\n\n# Load model and processor\nprint(\"Loading processor from local path...\")\ntry:\n    processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True) \n    print(\"Loading model from local path...\")\n    model = Wav2Vec2Model.from_pretrained(MODEL_PATH, trust_remote_code=True) \n    model.to(device)\n    model.eval()\n    print(\"Model and processor loaded successfully.\")\nexcept Exception as e:\n    print(f\"CRITICAL ERROR: FAILED TO LOAD MODEL FROM LOCAL PATH - {e}\")\n    raise \n\nall_embeddings = []\n\nprint(f\"Starting audio embedding generation in batches of {BATCH_SIZE}...\")\nprint(\"This will take 30-60+ minutes. Please be patient.\")\n\n# Process in batches\nfor i in tqdm(range(0, len(audio_paths), BATCH_SIZE)):\n    batch_paths = audio_paths[i:i + BATCH_SIZE]\n    # Filter out None values in case load_and_resample_audio failed severely, though it returns zeros now\n    batch_audio = [audio for audio in (load_and_resample_audio(path) for path in batch_paths) if audio is not None]\n\n    # Handle case where a whole batch failed to load (unlikely with zeros fallback)\n    if not batch_audio:\n        print(f\"Warning: Skipping empty batch starting at index {i}\")\n        # Need to append placeholder embeddings if skipping\n        batch_size_expected = len(batch_paths)\n        embedding_dim = model.config.hidden_size \n        zeros = np.zeros((batch_size_expected, embedding_dim))\n        all_embeddings.append(zeros)\n        continue\n\n    try:\n        inputs = processor(\n            batch_audio, \n            sampling_rate=TARGET_SAMPLE_RATE, \n            return_tensors=\"pt\", \n            padding=True, \n            truncation=True, \n            max_length=240000 # ~15 seconds max length\n        )\n    except Exception as e:\n        print(f\"Error during processor call for batch starting at index {i}: {e}\")\n        batch_size_actual = len(batch_audio) # Use actual loaded count\n        embedding_dim = model.config.hidden_size \n        zeros = np.zeros((batch_size_actual, embedding_dim))\n        all_embeddings.append(zeros)\n        continue # Skip this batch\n\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # --- MODIFICATION ---\n    # Simple mean pooling over the sequence length dimension (dim=1)\n    # This works even without an explicit attention mask from the processor.\n    batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n    # --- END MODIFICATION ---\n\n    all_embeddings.append(batch_embeddings.cpu().numpy())\n\nprint(\"Embedding generation complete. Concatenating results...\")\nif not all_embeddings:\n     print(\"Error: No embeddings were generated. Cannot save.\")\nelse:\n    try:\n        embeddings = np.concatenate(all_embeddings, axis=0)\n        np.save(OUTPUT_FILE, embeddings)\n\n        print(\"-\" * 30)\n        print(f\"✓ Success! Embeddings saved to {OUTPUT_FILE}\")\n        print(f\"Embedding shape: {embeddings.shape}\")\n        # Add a check for expected number of embeddings\n        if embeddings.shape[0] != len(audio_paths):\n            print(f\"Warning: Number of embeddings ({embeddings.shape[0]}) does not match number of audio paths ({len(audio_paths)}). Some might have failed.\")\n        print(f\"\\nYour '{OUTPUT_FILE}' file is now in the output directory '/kaggle/working/'.\")\n    except ValueError as e:\n        print(f\"Error during concatenation: {e}\")\n        print(\"This might happen if embedding shapes within batches are inconsistent.\")\n        # Optional: Add code here to inspect shapes in all_embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:52:26.291207Z","iopub.execute_input":"2025-10-23T20:52:26.291524Z","iopub.status.idle":"2025-10-23T21:07:40.219975Z","shell.execute_reply.started":"2025-10-23T20:52:26.291500Z","shell.execute_reply":"2025-10-23T21:07:40.219184Z"}},"outputs":[{"name":"stdout","text":"Script started.\nUsing device: cuda\nFound local model files at: /kaggle/input/meld-data/wave2vec-model. Proceeding...\nSuccessfully loaded CSV with 13706 rows.\nLoading processor from local path...\nLoading model from local path...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of Wav2Vec2Model were not initialized from the model checkpoint at /kaggle/input/meld-data/wave2vec-model and are newly initialized: ['masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model and processor loaded successfully.\nStarting audio embedding generation in batches of 32...\nThis will take 30-60+ minutes. Please be patient.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/429 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2cc7e7e3204935846a69ed8c3aeb1e"}},"metadata":{}},{"name":"stdout","text":"Embedding generation complete. Concatenating results...\n------------------------------\n✓ Success! Embeddings saved to meld-audio-embeddings.npy\nEmbedding shape: (13706, 768)\n\nYour 'meld-audio-embeddings.npy' file is now in the output directory '/kaggle/working/'.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls -lR /kaggle/input/meld-data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:12:09.637443Z","iopub.execute_input":"2025-10-23T21:12:09.637765Z","iopub.status.idle":"2025-10-23T21:12:09.809087Z","shell.execute_reply.started":"2025-10-23T21:12:09.637741Z","shell.execute_reply":"2025-10-23T21:12:09.808083Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/meld-data/:\ntotal 84504\n-rw-r--r-- 1 nobody nogroup 42104960 Oct 23 21:11 meld-audio-embeddings.npy\n-rw-r--r-- 1 nobody nogroup  2315511 Oct 23 21:11 MELD_complete_dataset.csv\n-rw-r--r-- 1 nobody nogroup 42104960 Oct 23 21:11 meld-text-embeddings.npy\ndrwxr-xr-x 2 nobody nogroup        0 Oct 23 21:11 wave2vec-model\n\n/kaggle/input/meld-data/wave2vec-model:\ntotal 368832\n-rw-r--r-- 1 nobody nogroup      1596 Oct 23 21:11 config.json\n-rw-r--r-- 1 nobody nogroup       159 Oct 23 21:11 preprocessor_config.json\n-rw-r--r-- 1 nobody nogroup 377667514 Oct 23 21:11 pytorch_model.bin\n-rw-r--r-- 1 nobody nogroup       163 Oct 23 21:11 tokenizer_config.json\n-rw-r--r-- 1 nobody nogroup       291 Oct 23 21:11 vocab.json\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nimport os\nimport time # To time training\n\n# --- 1. Configuration ---\nDATASET_PATH = \"/kaggle/input/meld-data/\"\nCSV_FILE = os.path.join(DATASET_PATH, \"MELD_complete_dataset.csv\")\nTEXT_EMBEDDINGS_FILE = os.path.join(DATASET_PATH, \"meld-text-embeddings.npy\")\nAUDIO_EMBEDDINGS_FILE = os.path.join(DATASET_PATH, \"meld-audio-embeddings.npy\")\n# MODEL_SAVE_PATH is now dynamic, defined in the training loop\n\n# Model Hyperparameters\nHIDDEN_UNITS_1 = 256\nHIDDEN_UNITS_2 = 128\nDROPOUT_RATE = 0.3\n# LEARNING_RATE is now a list\nLEARNING_RATES = [0.001, 0.0001, 1e-5] \nEPOCHS = 30\nBATCH_SIZE = 64\nPATIENCE = 5 # For early stopping\n\n# --- 2. Load Data ---\nprint(\"Loading data...\")\ntry:\n    df = pd.read_csv(CSV_FILE)\n    print(f\"✓ Loaded CSV: {len(df)} rows\")\n\n    X_text = np.load(TEXT_EMBEDDINGS_FILE)\n    print(f\"✓ Loaded Text Embeddings: Shape {X_text.shape}\")\n\n    X_audio = np.load(AUDIO_EMBEDDINGS_FILE)\n    print(f\"✓ Loaded Audio Embeddings: Shape {X_audio.shape}\")\n\n    if len(df) != X_text.shape[0] or len(df) != X_audio.shape[0]:\n        raise ValueError(f\"Mismatch in samples! CSV:{len(df)}, Text:{X_text.shape[0]}, Audio:{X_audio.shape[0]}\")\n\nexcept FileNotFoundError as e:\n    print(f\"Error loading files: {e}\")\n    print(\"Please ensure 'meld-data' dataset is added.\")\n    raise\n\n# --- 3. Prepare Data ---\nprint(\"\\nPreparing data...\")\nX_combined = np.concatenate((X_text, X_audio), axis=1)\nprint(f\"Combined Embeddings Shape: {X_combined.shape}\")\ninput_dim = X_combined.shape[1]\n\ny_text_labels = df['Emotion']\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y_text_labels)\nnum_classes = len(encoder.classes_)\nprint(f\"Found {num_classes} emotion classes: {encoder.classes_}\")\n\nX_combined_tensor = torch.tensor(X_combined, dtype=torch.float32)\ny_encoded_tensor = torch.tensor(y_encoded, dtype=torch.long)\n\nsplit_col = df['split'].values\ntrain_indices = np.where(split_col == 'train')[0]\ndev_indices = np.where(split_col == 'dev')[0]\ntest_indices = np.where(split_col == 'test')[0]\n\nX_train, y_train = X_combined_tensor[train_indices], y_encoded_tensor[train_indices]\nX_dev, y_dev = X_combined_tensor[dev_indices], y_encoded_tensor[dev_indices]\nX_test, y_test = X_combined_tensor[test_indices], y_encoded_tensor[test_indices]\n\nprint(f\"\\nData Split:\")\nprint(f\"Train samples: {len(X_train)}\")\nprint(f\"Dev samples:   {len(X_dev)}\")\nprint(f\"Test samples:  {len(X_test)}\")\n\ntrain_dataset = TensorDataset(X_train, y_train)\ndev_dataset = TensorDataset(X_dev, y_dev)\ntest_dataset = TensorDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ndev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Device setup (do once)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\nUsing device: {device}\")\n\n# --- 4. Define the Dense Network (PyTorch) ---\n# This class definition is used in the loop\nclass DenseClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes, h1=256, h2=128, dropout_rate=0.3):\n        super(DenseClassifier, self).__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, h1),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(h1, h2),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(h2, num_classes)\n        )\n    def forward(self, x):\n        return self.network(x)\n\n# --- Main Training & Evaluation Loop ---\n# Iterate over each learning rate\nfor lr in LEARNING_RATES:\n    print(f\"\\n=======================================================\")\n    print(f\"=== STARTING TRAINING RUN: LEARNING RATE = {lr} ===\")\n    print(f\"=======================================================\")\n    \n    # --- 4. Define the Dense Network (PyTorch) ---\n    print(\"\\nBuilding model...\")\n    model = DenseClassifier(input_dim, num_classes, HIDDEN_UNITS_1, HIDDEN_UNITS_2, DROPOUT_RATE)\n    print(model)\n\n    # --- 5. Setup Training ---\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr) # Use current LR\n    \n    # Define dynamic model save path\n    MODEL_SAVE_PATH = f\"meld_emotion_classifier_lr_{lr}.pth\"\n\n    best_val_accuracy = 0.0\n    epochs_no_improve = 0\n    best_model_state = None\n\n    # --- 6. Training Loop ---\n    print(\"\\nStarting training...\")\n    start_time = time.time()\n\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        train_preds, train_targets = [], []\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.cpu().numpy())\n            train_targets.extend(labels.cpu().numpy())\n\n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = accuracy_score(train_targets, train_preds)\n\n        model.eval()\n        val_loss = 0.0\n        val_preds, val_targets = [], []\n        with torch.no_grad():\n            for inputs, labels in dev_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                val_preds.extend(predicted.cpu().numpy())\n                val_targets.extend(labels.cpu().numpy())\n\n        val_loss /= len(dev_loader)\n        val_accuracy = accuracy_score(val_targets, val_preds)\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc*100:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy*100:.2f}%\")\n\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            epochs_no_improve = 0\n            best_model_state = model.state_dict().copy() # Use .copy()\n            print(f\"  New best validation accuracy: {best_val_accuracy*100:.2f}%. Saving model state...\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= PATIENCE:\n                print(f\"\\nEarly stopping triggered after {epoch+1} epochs.\")\n                break\n\n    end_time = time.time()\n    print(f\"\\nTraining complete. Total time: {end_time - start_time:.2f} seconds.\")\n\n    # --- 7. Save the Best Model Weights ---\n    if best_model_state:\n        print(f\"\\nSaving best model weights to {MODEL_SAVE_PATH}...\")\n        torch.save(best_model_state, MODEL_SAVE_PATH) # <-- Save the state dictionary\n        print(\"✓ Model saved.\")\n        # Load the best weights back into the model for evaluation\n        model.load_state_dict(best_model_state)\n    else:\n         print(\"\\nWarning: No best model state saved. Evaluating with final model state.\")\n\n    # --- 8. Evaluate on Test Set ---\n    model.eval()\n    test_preds, test_targets = [], []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.cpu().numpy())\n            test_targets.extend(labels.cpu().numpy())\n\n    test_accuracy = accuracy_score(test_targets, test_preds)\n    print(f\"\\nEvaluating on Test Set (for LR={lr})...\")\n    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n    print(\"\\nClassification Report (Test Set):\")\n    # Use the integer labels for classification report\n    print(classification_report(test_targets, test_preds, target_names=encoder.classes_, zero_division=0))\n\nprint(\"\\nAll training runs finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:59:30.064456Z","iopub.execute_input":"2025-10-23T21:59:30.065072Z","iopub.status.idle":"2025-10-23T22:00:03.365824Z","shell.execute_reply.started":"2025-10-23T21:59:30.065049Z","shell.execute_reply":"2025-10-23T22:00:03.365063Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n✓ Loaded CSV: 13706 rows\n✓ Loaded Text Embeddings: Shape (13706, 768)\n✓ Loaded Audio Embeddings: Shape (13706, 768)\n\nPreparing data...\nCombined Embeddings Shape: (13706, 1536)\nFound 7 emotion classes: ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n\nData Split:\nTrain samples: 9988\nDev samples:   1108\nTest samples:  2610\n\nUsing device: cuda\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 0.001 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/30 | Train Loss: 1.4732 | Train Acc: 49.14% | Val Loss: 1.4971 | Val Acc: 48.10%\n  New best validation accuracy: 48.10%. Saving model state...\nEpoch 2/30 | Train Loss: 1.4007 | Train Acc: 53.00% | Val Loss: 1.4435 | Val Acc: 48.92%\n  New best validation accuracy: 48.92%. Saving model state...\nEpoch 3/30 | Train Loss: 1.3659 | Train Acc: 54.21% | Val Loss: 1.4275 | Val Acc: 49.73%\n  New best validation accuracy: 49.73%. Saving model state...\nEpoch 4/30 | Train Loss: 1.3465 | Train Acc: 54.56% | Val Loss: 1.4262 | Val Acc: 50.54%\n  New best validation accuracy: 50.54%. Saving model state...\nEpoch 5/30 | Train Loss: 1.3348 | Train Acc: 54.72% | Val Loss: 1.4167 | Val Acc: 50.54%\nEpoch 6/30 | Train Loss: 1.3205 | Train Acc: 55.25% | Val Loss: 1.4281 | Val Acc: 50.90%\n  New best validation accuracy: 50.90%. Saving model state...\nEpoch 7/30 | Train Loss: 1.3148 | Train Acc: 55.63% | Val Loss: 1.4177 | Val Acc: 51.17%\n  New best validation accuracy: 51.17%. Saving model state...\nEpoch 8/30 | Train Loss: 1.3091 | Train Acc: 55.52% | Val Loss: 1.4285 | Val Acc: 50.45%\nEpoch 9/30 | Train Loss: 1.3220 | Train Acc: 55.74% | Val Loss: 1.4109 | Val Acc: 51.17%\nEpoch 10/30 | Train Loss: 1.3081 | Train Acc: 55.92% | Val Loss: 1.4308 | Val Acc: 50.63%\nEpoch 11/30 | Train Loss: 1.2900 | Train Acc: 56.67% | Val Loss: 1.4079 | Val Acc: 50.90%\nEpoch 12/30 | Train Loss: 1.2809 | Train Acc: 56.83% | Val Loss: 1.4450 | Val Acc: 51.53%\n  New best validation accuracy: 51.53%. Saving model state...\nEpoch 13/30 | Train Loss: 1.2791 | Train Acc: 56.98% | Val Loss: 1.3975 | Val Acc: 52.98%\n  New best validation accuracy: 52.98%. Saving model state...\nEpoch 14/30 | Train Loss: 1.2834 | Train Acc: 56.71% | Val Loss: 1.4589 | Val Acc: 51.35%\nEpoch 15/30 | Train Loss: 1.2838 | Train Acc: 56.70% | Val Loss: 1.3987 | Val Acc: 52.71%\nEpoch 16/30 | Train Loss: 1.2803 | Train Acc: 56.51% | Val Loss: 1.4105 | Val Acc: 52.44%\nEpoch 17/30 | Train Loss: 1.2673 | Train Acc: 56.67% | Val Loss: 1.4036 | Val Acc: 51.81%\nEpoch 18/30 | Train Loss: 1.2612 | Train Acc: 57.34% | Val Loss: 1.3968 | Val Acc: 52.17%\n\nEarly stopping triggered after 18 epochs.\n\nTraining complete. Total time: 7.62 seconds.\n\nSaving best model weights to meld_emotion_classifier_lr_0.001.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=0.001)...\nTest Accuracy: 56.32%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.31      0.06      0.11       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.00      0.00      0.00        50\n         joy       0.41      0.42      0.42       402\n     neutral       0.63      0.92      0.75      1256\n     sadness       0.00      0.00      0.00       208\n    surprise       0.42      0.43      0.42       281\n\n    accuracy                           0.56      2610\n   macro avg       0.25      0.26      0.24      2610\nweighted avg       0.45      0.56      0.48      2610\n\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 0.0001 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/30 | Train Loss: 1.5757 | Train Acc: 46.39% | Val Loss: 1.5724 | Val Acc: 42.42%\n  New best validation accuracy: 42.42%. Saving model state...\nEpoch 2/30 | Train Loss: 1.4590 | Train Acc: 49.42% | Val Loss: 1.5186 | Val Acc: 46.03%\n  New best validation accuracy: 46.03%. Saving model state...\nEpoch 3/30 | Train Loss: 1.4059 | Train Acc: 52.14% | Val Loss: 1.4904 | Val Acc: 48.10%\n  New best validation accuracy: 48.10%. Saving model state...\nEpoch 4/30 | Train Loss: 1.3761 | Train Acc: 53.22% | Val Loss: 1.4664 | Val Acc: 48.29%\n  New best validation accuracy: 48.29%. Saving model state...\nEpoch 5/30 | Train Loss: 1.3570 | Train Acc: 53.70% | Val Loss: 1.4665 | Val Acc: 48.56%\n  New best validation accuracy: 48.56%. Saving model state...\nEpoch 6/30 | Train Loss: 1.3414 | Train Acc: 54.45% | Val Loss: 1.4341 | Val Acc: 49.19%\n  New best validation accuracy: 49.19%. Saving model state...\nEpoch 7/30 | Train Loss: 1.3387 | Train Acc: 55.03% | Val Loss: 1.4253 | Val Acc: 49.73%\n  New best validation accuracy: 49.73%. Saving model state...\nEpoch 8/30 | Train Loss: 1.3300 | Train Acc: 55.44% | Val Loss: 1.4267 | Val Acc: 49.82%\n  New best validation accuracy: 49.82%. Saving model state...\nEpoch 9/30 | Train Loss: 1.3103 | Train Acc: 55.57% | Val Loss: 1.4236 | Val Acc: 51.17%\n  New best validation accuracy: 51.17%. Saving model state...\nEpoch 10/30 | Train Loss: 1.3087 | Train Acc: 55.76% | Val Loss: 1.4257 | Val Acc: 50.81%\nEpoch 11/30 | Train Loss: 1.3076 | Train Acc: 56.12% | Val Loss: 1.4340 | Val Acc: 50.27%\nEpoch 12/30 | Train Loss: 1.2974 | Train Acc: 56.51% | Val Loss: 1.4158 | Val Acc: 51.35%\n  New best validation accuracy: 51.35%. Saving model state...\nEpoch 13/30 | Train Loss: 1.2990 | Train Acc: 56.47% | Val Loss: 1.4066 | Val Acc: 51.71%\n  New best validation accuracy: 51.71%. Saving model state...\nEpoch 14/30 | Train Loss: 1.2841 | Train Acc: 56.52% | Val Loss: 1.4187 | Val Acc: 51.53%\nEpoch 15/30 | Train Loss: 1.2846 | Train Acc: 56.75% | Val Loss: 1.4100 | Val Acc: 51.71%\nEpoch 16/30 | Train Loss: 1.2789 | Train Acc: 56.90% | Val Loss: 1.4145 | Val Acc: 51.81%\n  New best validation accuracy: 51.81%. Saving model state...\nEpoch 17/30 | Train Loss: 1.2726 | Train Acc: 57.01% | Val Loss: 1.4033 | Val Acc: 52.08%\n  New best validation accuracy: 52.08%. Saving model state...\nEpoch 18/30 | Train Loss: 1.2679 | Train Acc: 57.24% | Val Loss: 1.4167 | Val Acc: 52.08%\nEpoch 19/30 | Train Loss: 1.2657 | Train Acc: 57.29% | Val Loss: 1.4038 | Val Acc: 52.17%\n  New best validation accuracy: 52.17%. Saving model state...\nEpoch 20/30 | Train Loss: 1.2654 | Train Acc: 57.54% | Val Loss: 1.4124 | Val Acc: 51.81%\nEpoch 21/30 | Train Loss: 1.2556 | Train Acc: 57.31% | Val Loss: 1.4093 | Val Acc: 52.17%\nEpoch 22/30 | Train Loss: 1.2538 | Train Acc: 58.12% | Val Loss: 1.3923 | Val Acc: 52.80%\n  New best validation accuracy: 52.80%. Saving model state...\nEpoch 23/30 | Train Loss: 1.2450 | Train Acc: 58.08% | Val Loss: 1.4514 | Val Acc: 52.71%\nEpoch 24/30 | Train Loss: 1.2471 | Train Acc: 57.83% | Val Loss: 1.4079 | Val Acc: 52.44%\nEpoch 25/30 | Train Loss: 1.2387 | Train Acc: 58.21% | Val Loss: 1.3906 | Val Acc: 52.80%\nEpoch 26/30 | Train Loss: 1.2422 | Train Acc: 57.98% | Val Loss: 1.3905 | Val Acc: 52.44%\nEpoch 27/30 | Train Loss: 1.2391 | Train Acc: 58.37% | Val Loss: 1.3976 | Val Acc: 52.89%\n  New best validation accuracy: 52.89%. Saving model state...\nEpoch 28/30 | Train Loss: 1.2378 | Train Acc: 58.26% | Val Loss: 1.3910 | Val Acc: 52.71%\nEpoch 29/30 | Train Loss: 1.2310 | Train Acc: 58.29% | Val Loss: 1.3925 | Val Acc: 52.17%\nEpoch 30/30 | Train Loss: 1.2335 | Train Acc: 58.46% | Val Loss: 1.3996 | Val Acc: 52.98%\n  New best validation accuracy: 52.98%. Saving model state...\n\nTraining complete. Total time: 12.68 seconds.\n\nSaving best model weights to meld_emotion_classifier_lr_0.0001.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=0.0001)...\nTest Accuracy: 57.51%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.41      0.12      0.19       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.00      0.00      0.00        50\n         joy       0.42      0.48      0.45       402\n     neutral       0.64      0.91      0.75      1256\n     sadness       0.00      0.00      0.00       208\n    surprise       0.50      0.43      0.46       281\n\n    accuracy                           0.58      2610\n   macro avg       0.28      0.28      0.26      2610\nweighted avg       0.48      0.58      0.50      2610\n\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 1e-05 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/30 | Train Loss: 1.7603 | Train Acc: 43.67% | Val Loss: 1.6901 | Val Acc: 42.33%\n  New best validation accuracy: 42.33%. Saving model state...\nEpoch 2/30 | Train Loss: 1.5931 | Train Acc: 47.14% | Val Loss: 1.6413 | Val Acc: 42.33%\nEpoch 3/30 | Train Loss: 1.5562 | Train Acc: 47.19% | Val Loss: 1.6212 | Val Acc: 42.33%\nEpoch 4/30 | Train Loss: 1.5337 | Train Acc: 47.15% | Val Loss: 1.6038 | Val Acc: 42.33%\nEpoch 5/30 | Train Loss: 1.5212 | Train Acc: 47.22% | Val Loss: 1.5925 | Val Acc: 42.33%\nEpoch 6/30 | Train Loss: 1.5056 | Train Acc: 47.35% | Val Loss: 1.5762 | Val Acc: 42.42%\n  New best validation accuracy: 42.42%. Saving model state...\nEpoch 7/30 | Train Loss: 1.4923 | Train Acc: 47.64% | Val Loss: 1.5648 | Val Acc: 42.69%\n  New best validation accuracy: 42.69%. Saving model state...\nEpoch 8/30 | Train Loss: 1.4797 | Train Acc: 48.08% | Val Loss: 1.5506 | Val Acc: 43.23%\n  New best validation accuracy: 43.23%. Saving model state...\nEpoch 9/30 | Train Loss: 1.4664 | Train Acc: 48.81% | Val Loss: 1.5447 | Val Acc: 43.86%\n  New best validation accuracy: 43.86%. Saving model state...\nEpoch 10/30 | Train Loss: 1.4527 | Train Acc: 49.32% | Val Loss: 1.5303 | Val Acc: 45.04%\n  New best validation accuracy: 45.04%. Saving model state...\nEpoch 11/30 | Train Loss: 1.4466 | Train Acc: 49.91% | Val Loss: 1.5229 | Val Acc: 45.67%\n  New best validation accuracy: 45.67%. Saving model state...\nEpoch 12/30 | Train Loss: 1.4362 | Train Acc: 50.43% | Val Loss: 1.5122 | Val Acc: 46.21%\n  New best validation accuracy: 46.21%. Saving model state...\nEpoch 13/30 | Train Loss: 1.4319 | Train Acc: 51.33% | Val Loss: 1.5063 | Val Acc: 46.93%\n  New best validation accuracy: 46.93%. Saving model state...\nEpoch 14/30 | Train Loss: 1.4162 | Train Acc: 51.32% | Val Loss: 1.5003 | Val Acc: 47.56%\n  New best validation accuracy: 47.56%. Saving model state...\nEpoch 15/30 | Train Loss: 1.4190 | Train Acc: 51.82% | Val Loss: 1.4971 | Val Acc: 47.20%\nEpoch 16/30 | Train Loss: 1.4119 | Train Acc: 51.67% | Val Loss: 1.4913 | Val Acc: 47.83%\n  New best validation accuracy: 47.83%. Saving model state...\nEpoch 17/30 | Train Loss: 1.4083 | Train Acc: 52.10% | Val Loss: 1.4872 | Val Acc: 48.01%\n  New best validation accuracy: 48.01%. Saving model state...\nEpoch 18/30 | Train Loss: 1.4031 | Train Acc: 52.53% | Val Loss: 1.4848 | Val Acc: 48.01%\nEpoch 19/30 | Train Loss: 1.3904 | Train Acc: 52.72% | Val Loss: 1.4785 | Val Acc: 48.10%\n  New best validation accuracy: 48.10%. Saving model state...\nEpoch 20/30 | Train Loss: 1.3904 | Train Acc: 52.81% | Val Loss: 1.4753 | Val Acc: 48.29%\n  New best validation accuracy: 48.29%. Saving model state...\nEpoch 21/30 | Train Loss: 1.3833 | Train Acc: 53.45% | Val Loss: 1.4750 | Val Acc: 48.19%\nEpoch 22/30 | Train Loss: 1.3804 | Train Acc: 52.79% | Val Loss: 1.4710 | Val Acc: 48.29%\nEpoch 23/30 | Train Loss: 1.3761 | Train Acc: 53.52% | Val Loss: 1.4656 | Val Acc: 48.38%\n  New best validation accuracy: 48.38%. Saving model state...\nEpoch 24/30 | Train Loss: 1.3754 | Train Acc: 53.70% | Val Loss: 1.4642 | Val Acc: 48.47%\n  New best validation accuracy: 48.47%. Saving model state...\nEpoch 25/30 | Train Loss: 1.3704 | Train Acc: 53.66% | Val Loss: 1.4623 | Val Acc: 48.38%\nEpoch 26/30 | Train Loss: 1.3679 | Train Acc: 53.84% | Val Loss: 1.4576 | Val Acc: 48.65%\n  New best validation accuracy: 48.65%. Saving model state...\nEpoch 27/30 | Train Loss: 1.3602 | Train Acc: 53.86% | Val Loss: 1.4609 | Val Acc: 48.56%\nEpoch 28/30 | Train Loss: 1.3699 | Train Acc: 53.97% | Val Loss: 1.4541 | Val Acc: 48.65%\nEpoch 29/30 | Train Loss: 1.3622 | Train Acc: 54.42% | Val Loss: 1.4550 | Val Acc: 48.65%\nEpoch 30/30 | Train Loss: 1.3549 | Train Acc: 54.03% | Val Loss: 1.4537 | Val Acc: 48.74%\n  New best validation accuracy: 48.74%. Saving model state...\n\nTraining complete. Total time: 12.60 seconds.\n\nSaving best model weights to meld_emotion_classifier_lr_1e-05.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=1e-05)...\nTest Accuracy: 55.25%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.00      0.00      0.00       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.00      0.00      0.00        50\n         joy       0.37      0.45      0.40       402\n     neutral       0.60      0.96      0.74      1256\n     sadness       0.00      0.00      0.00       208\n    surprise       0.59      0.20      0.30       281\n\n    accuracy                           0.55      2610\n   macro avg       0.22      0.23      0.21      2610\nweighted avg       0.41      0.55      0.45      2610\n\n\nAll training runs finished.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nimport os\nimport time # To time training\nimport math # For sqrt in class weights\n\n# --- 1. Configuration ---\nDATASET_PATH = \"/kaggle/input/meld-data/\"\nCSV_FILE = os.path.join(DATASET_PATH, \"MELD_complete_dataset.csv\")\nTEXT_EMBEDDINGS_FILE = os.path.join(DATASET_PATH, \"meld-text-embeddings.npy\")\nAUDIO_EMBEDDINGS_FILE = os.path.join(DATASET_PATH, \"meld-audio-embeddings.npy\")\n# MODEL_SAVE_PATH is dynamic\n\n# Model Hyperparameters\nHIDDEN_UNITS_1 = 256\nHIDDEN_UNITS_2 = 128\nDROPOUT_RATE = 0.3\nLEARNING_RATES = [0.001, 0.0001, 1e-5]\nEPOCHS = 40 # Increased slightly to allow more time with weights\nBATCH_SIZE = 64\nPATIENCE = 7 # Increased slightly\n\n# --- 2. Load Data ---\nprint(\"Loading data...\")\ntry:\n    df = pd.read_csv(CSV_FILE)\n    print(f\"✓ Loaded CSV: {len(df)} rows\")\n    X_text = np.load(TEXT_EMBEDDINGS_FILE)\n    print(f\"✓ Loaded Text Embeddings: Shape {X_text.shape}\")\n    X_audio = np.load(AUDIO_EMBEDDINGS_FILE)\n    print(f\"✓ Loaded Audio Embeddings: Shape {X_audio.shape}\")\n    if len(df) != X_text.shape[0] or len(df) != X_audio.shape[0]:\n        raise ValueError(\"Mismatch in samples!\")\nexcept FileNotFoundError as e:\n    print(f\"Error loading files: {e}\")\n    raise\n\n# --- 3. Prepare Data ---\nprint(\"\\nPreparing data...\")\nX_combined = np.concatenate((X_text, X_audio), axis=1)\nprint(f\"Combined Embeddings Shape: {X_combined.shape}\")\ninput_dim = X_combined.shape[1]\n\ny_text_labels = df['Emotion']\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y_text_labels)\nnum_classes = len(encoder.classes_)\nprint(f\"Found {num_classes} emotion classes: {encoder.classes_}\")\n\nX_combined_tensor = torch.tensor(X_combined, dtype=torch.float32)\ny_encoded_tensor = torch.tensor(y_encoded, dtype=torch.long)\n\nsplit_col = df['split'].values\ntrain_indices = np.where(split_col == 'train')[0]\ndev_indices = np.where(split_col == 'dev')[0]\ntest_indices = np.where(split_col == 'test')[0]\n\nX_train, y_train = X_combined_tensor[train_indices], y_encoded_tensor[train_indices]\nX_dev, y_dev = X_combined_tensor[dev_indices], y_encoded_tensor[dev_indices]\nX_test, y_test = X_combined_tensor[test_indices], y_encoded_tensor[test_indices]\n\nprint(f\"\\nData Split:\")\nprint(f\"Train samples: {len(X_train)}\")\nprint(f\"Dev samples:   {len(X_dev)}\")\nprint(f\"Test samples:  {len(X_test)}\")\n\ntrain_dataset = TensorDataset(X_train, y_train)\ndev_dataset = TensorDataset(X_dev, y_dev)\ntest_dataset = TensorDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\ndev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\nUsing device: {device}\")\n\n# --- 4. Define Dense Network (Unchanged) ---\nclass DenseClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes, h1=256, h2=128, dropout_rate=0.3):\n        super(DenseClassifier, self).__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, h1),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(h1, h2),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(h2, num_classes)\n        )\n    def forward(self, x):\n        return self.network(x)\n\n# --- 5. Class Weight Calculation Function (NEW) ---\ndef calculate_class_weights(labels, num_classes, device):\n    \"\"\" Calculate less aggressive weights using sqrt of inverse frequency \"\"\"\n    if isinstance(labels, torch.Tensor):\n        labels_np = labels.cpu().numpy() # Ensure numpy array for calculation\n    else:\n        labels_np = labels # Assume it's already numpy or similar\n\n    unique, counts = np.unique(labels_np, return_counts=True)\n    total = len(labels_np)\n    weights = torch.zeros(num_classes, device=device)\n    for cls_idx, count in zip(unique, counts):\n        if count > 0:\n            weights[cls_idx] = math.sqrt(total / count)\n\n    # Normalize weights (optional but recommended)\n    weights = weights / weights.sum() * num_classes\n    print(f\"Calculated Class Weights (sqrt inverse freq): {weights}\")\n    return weights\n\n# --- Calculate weights ONCE using the training data ---\nprint(\"\\nCalculating class weights for the loss function...\")\n# Pass y_train tensor directly, function handles conversion\nclass_weights = calculate_class_weights(y_train, num_classes, device)\n\n# --- Main Training & Evaluation Loop ---\nfor lr in LEARNING_RATES:\n    print(f\"\\n=======================================================\")\n    print(f\"=== STARTING TRAINING RUN: LEARNING RATE = {lr} ===\")\n    print(f\"=======================================================\")\n\n    print(\"\\nBuilding model...\")\n    model = DenseClassifier(input_dim, num_classes, HIDDEN_UNITS_1, HIDDEN_UNITS_2, DROPOUT_RATE)\n    print(model)\n    model.to(device)\n\n    # --- Setup Training with WEIGHTED LOSS ---\n    criterion = nn.CrossEntropyLoss(weight=class_weights) # Pass weights here\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    MODEL_SAVE_PATH = f\"meld_emotion_classifier_weighted_lr_{lr}.pth\" # Updated save name\n\n    best_val_accuracy = 0.0\n    epochs_no_improve = 0\n    best_model_state = None\n\n    print(\"\\nStarting training...\")\n    start_time = time.time()\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        train_preds, train_targets = [], []\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels) # Loss calculation uses weights\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            train_preds.extend(predicted.cpu().numpy())\n            train_targets.extend(labels.cpu().numpy())\n\n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = accuracy_score(train_targets, train_preds)\n\n        # --- Validation ---\n        model.eval()\n        val_loss = 0.0\n        val_preds, val_targets = [], []\n        with torch.no_grad():\n            for inputs, labels in dev_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels) # Can use weighted loss for val too\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                val_preds.extend(predicted.cpu().numpy())\n                val_targets.extend(labels.cpu().numpy())\n\n        val_loss /= len(dev_loader)\n        val_accuracy = accuracy_score(val_targets, val_preds)\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc*100:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy*100:.2f}%\")\n\n        # --- Early Stopping Check ---\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            epochs_no_improve = 0\n            best_model_state = model.state_dict().copy()\n            print(f\"  New best validation accuracy: {best_val_accuracy*100:.2f}%. Saving model state...\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= PATIENCE:\n                print(f\"\\nEarly stopping triggered after {epoch+1} epochs.\")\n                break\n\n    end_time = time.time()\n    print(f\"\\nTraining complete for LR={lr}. Total time: {end_time - start_time:.2f} seconds.\")\n\n    # --- Save and Evaluate Best Model for this LR ---\n    if best_model_state:\n        print(f\"\\nSaving best model weights to {MODEL_SAVE_PATH}...\")\n        torch.save(best_model_state, MODEL_SAVE_PATH)\n        print(\"✓ Model saved.\")\n        model.load_state_dict(best_model_state) # Load best state for testing\n    else:\n         print(\"\\nWarning: No best model state saved.\")\n\n    model.eval()\n    test_preds, test_targets = [], []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            test_preds.extend(predicted.cpu().numpy())\n            test_targets.extend(labels.cpu().numpy())\n\n    test_accuracy = accuracy_score(test_targets, test_preds)\n    print(f\"\\nEvaluating on Test Set (for LR={lr})...\")\n    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n    print(\"\\nClassification Report (Test Set):\")\n    print(classification_report(test_targets, test_preds, target_names=encoder.classes_, zero_division=0))\n\nprint(\"\\nAll training runs finished.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T07:01:47.042167Z","iopub.execute_input":"2025-10-24T07:01:47.042757Z","iopub.status.idle":"2025-10-24T07:03:00.246290Z","shell.execute_reply.started":"2025-10-24T07:01:47.042737Z","shell.execute_reply":"2025-10-24T07:03:00.245324Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n✓ Loaded CSV: 13706 rows\n✓ Loaded Text Embeddings: Shape (13706, 768)\n✓ Loaded Audio Embeddings: Shape (13706, 768)\n\nPreparing data...\nCombined Embeddings Shape: (13706, 1536)\nFound 7 emotion classes: ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n\nData Split:\nTrain samples: 9988\nDev samples:   1108\nTest samples:  2610\n\nUsing device: cuda\n\nCalculating class weights for the loss function...\nCalculated Class Weights (sqrt inverse freq): tensor([0.8165, 1.6516, 1.6608, 0.6512, 0.3962, 1.0404, 0.7833],\n       device='cuda:0')\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 0.001 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/40 | Train Loss: 1.7732 | Train Acc: 48.27% | Val Loss: 1.7218 | Val Acc: 47.38%\n  New best validation accuracy: 47.38%. Saving model state...\nEpoch 2/40 | Train Loss: 1.6788 | Train Acc: 52.06% | Val Loss: 1.7237 | Val Acc: 49.10%\n  New best validation accuracy: 49.10%. Saving model state...\nEpoch 3/40 | Train Loss: 1.6572 | Train Acc: 52.83% | Val Loss: 1.7118 | Val Acc: 49.82%\n  New best validation accuracy: 49.82%. Saving model state...\nEpoch 4/40 | Train Loss: 1.6451 | Train Acc: 52.95% | Val Loss: 1.6778 | Val Acc: 50.90%\n  New best validation accuracy: 50.90%. Saving model state...\nEpoch 5/40 | Train Loss: 1.6333 | Train Acc: 53.39% | Val Loss: 1.7369 | Val Acc: 50.81%\nEpoch 6/40 | Train Loss: 1.6258 | Train Acc: 53.81% | Val Loss: 1.7738 | Val Acc: 37.73%\nEpoch 7/40 | Train Loss: 1.6238 | Train Acc: 54.52% | Val Loss: 1.6640 | Val Acc: 50.54%\nEpoch 8/40 | Train Loss: 1.6113 | Train Acc: 54.59% | Val Loss: 1.7861 | Val Acc: 51.08%\n  New best validation accuracy: 51.08%. Saving model state...\nEpoch 9/40 | Train Loss: 1.6083 | Train Acc: 53.35% | Val Loss: 1.6690 | Val Acc: 47.83%\nEpoch 10/40 | Train Loss: 1.5982 | Train Acc: 53.88% | Val Loss: 1.7004 | Val Acc: 48.83%\nEpoch 11/40 | Train Loss: 1.6119 | Train Acc: 54.08% | Val Loss: 1.7121 | Val Acc: 50.81%\nEpoch 12/40 | Train Loss: 1.6075 | Train Acc: 53.62% | Val Loss: 1.6690 | Val Acc: 52.26%\n  New best validation accuracy: 52.26%. Saving model state...\nEpoch 13/40 | Train Loss: 1.5942 | Train Acc: 54.66% | Val Loss: 1.7343 | Val Acc: 51.08%\nEpoch 14/40 | Train Loss: 1.5865 | Train Acc: 54.31% | Val Loss: 1.6978 | Val Acc: 50.99%\nEpoch 15/40 | Train Loss: 1.5821 | Train Acc: 54.54% | Val Loss: 1.6457 | Val Acc: 52.62%\n  New best validation accuracy: 52.62%. Saving model state...\nEpoch 16/40 | Train Loss: 1.5779 | Train Acc: 53.96% | Val Loss: 1.6763 | Val Acc: 52.08%\nEpoch 17/40 | Train Loss: 1.5776 | Train Acc: 54.26% | Val Loss: 1.6828 | Val Acc: 52.98%\n  New best validation accuracy: 52.98%. Saving model state...\nEpoch 18/40 | Train Loss: 1.5671 | Train Acc: 54.49% | Val Loss: 1.6396 | Val Acc: 50.81%\nEpoch 19/40 | Train Loss: 1.5707 | Train Acc: 54.39% | Val Loss: 1.6751 | Val Acc: 52.53%\nEpoch 20/40 | Train Loss: 1.5662 | Train Acc: 54.24% | Val Loss: 1.7040 | Val Acc: 52.53%\nEpoch 21/40 | Train Loss: 1.5541 | Train Acc: 55.18% | Val Loss: 1.7596 | Val Acc: 50.99%\nEpoch 22/40 | Train Loss: 1.5614 | Train Acc: 54.22% | Val Loss: 1.6538 | Val Acc: 51.90%\nEpoch 23/40 | Train Loss: 1.5501 | Train Acc: 54.83% | Val Loss: 1.6858 | Val Acc: 51.53%\nEpoch 24/40 | Train Loss: 1.5522 | Train Acc: 54.72% | Val Loss: 1.6455 | Val Acc: 49.10%\n\nEarly stopping triggered after 24 epochs.\n\nTraining complete for LR=0.001. Total time: 17.24 seconds.\n\nSaving best model weights to meld_emotion_classifier_weighted_lr_0.001.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=0.001)...\nTest Accuracy: 50.00%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.34      0.25      0.29       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.04      0.02      0.03        50\n         joy       0.47      0.30      0.37       402\n     neutral       0.69      0.70      0.69      1256\n     sadness       0.24      0.18      0.20       208\n    surprise       0.29      0.64      0.40       281\n\n    accuracy                           0.50      2610\n   macro avg       0.29      0.30      0.28      2610\nweighted avg       0.50      0.50      0.49      2610\n\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 0.0001 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/40 | Train Loss: 1.8207 | Train Acc: 46.73% | Val Loss: 1.8046 | Val Acc: 45.58%\n  New best validation accuracy: 45.58%. Saving model state...\nEpoch 2/40 | Train Loss: 1.7322 | Train Acc: 50.78% | Val Loss: 1.7438 | Val Acc: 47.56%\n  New best validation accuracy: 47.56%. Saving model state...\nEpoch 3/40 | Train Loss: 1.7017 | Train Acc: 52.00% | Val Loss: 1.7180 | Val Acc: 48.47%\n  New best validation accuracy: 48.47%. Saving model state...\nEpoch 4/40 | Train Loss: 1.6687 | Train Acc: 53.14% | Val Loss: 1.7178 | Val Acc: 47.83%\nEpoch 5/40 | Train Loss: 1.6529 | Train Acc: 53.60% | Val Loss: 1.7007 | Val Acc: 49.28%\n  New best validation accuracy: 49.28%. Saving model state...\nEpoch 6/40 | Train Loss: 1.6419 | Train Acc: 53.91% | Val Loss: 1.6956 | Val Acc: 50.81%\n  New best validation accuracy: 50.81%. Saving model state...\nEpoch 7/40 | Train Loss: 1.6266 | Train Acc: 54.18% | Val Loss: 1.6820 | Val Acc: 50.63%\nEpoch 8/40 | Train Loss: 1.6192 | Train Acc: 54.57% | Val Loss: 1.6749 | Val Acc: 51.08%\n  New best validation accuracy: 51.08%. Saving model state...\nEpoch 9/40 | Train Loss: 1.6109 | Train Acc: 55.44% | Val Loss: 1.6718 | Val Acc: 50.54%\nEpoch 10/40 | Train Loss: 1.6086 | Train Acc: 55.32% | Val Loss: 1.6748 | Val Acc: 50.72%\nEpoch 11/40 | Train Loss: 1.5991 | Train Acc: 55.22% | Val Loss: 1.6643 | Val Acc: 49.91%\nEpoch 12/40 | Train Loss: 1.5955 | Train Acc: 55.14% | Val Loss: 1.6693 | Val Acc: 52.71%\n  New best validation accuracy: 52.71%. Saving model state...\nEpoch 13/40 | Train Loss: 1.5889 | Train Acc: 55.81% | Val Loss: 1.6599 | Val Acc: 50.81%\nEpoch 14/40 | Train Loss: 1.5773 | Train Acc: 55.15% | Val Loss: 1.6549 | Val Acc: 51.62%\nEpoch 15/40 | Train Loss: 1.5693 | Train Acc: 55.86% | Val Loss: 1.6645 | Val Acc: 51.81%\nEpoch 16/40 | Train Loss: 1.5621 | Train Acc: 56.11% | Val Loss: 1.6575 | Val Acc: 50.90%\nEpoch 17/40 | Train Loss: 1.5620 | Train Acc: 55.99% | Val Loss: 1.6390 | Val Acc: 51.26%\nEpoch 18/40 | Train Loss: 1.5517 | Train Acc: 56.12% | Val Loss: 1.6873 | Val Acc: 53.16%\n  New best validation accuracy: 53.16%. Saving model state...\nEpoch 19/40 | Train Loss: 1.5511 | Train Acc: 56.17% | Val Loss: 1.6522 | Val Acc: 52.80%\nEpoch 20/40 | Train Loss: 1.5487 | Train Acc: 55.93% | Val Loss: 1.6672 | Val Acc: 51.99%\nEpoch 21/40 | Train Loss: 1.5491 | Train Acc: 56.58% | Val Loss: 1.6313 | Val Acc: 51.62%\nEpoch 22/40 | Train Loss: 1.5320 | Train Acc: 56.53% | Val Loss: 1.6448 | Val Acc: 51.35%\nEpoch 23/40 | Train Loss: 1.5302 | Train Acc: 56.20% | Val Loss: 1.6397 | Val Acc: 52.26%\nEpoch 24/40 | Train Loss: 1.5260 | Train Acc: 56.51% | Val Loss: 1.6408 | Val Acc: 52.35%\nEpoch 25/40 | Train Loss: 1.5238 | Train Acc: 56.95% | Val Loss: 1.6430 | Val Acc: 51.99%\n\nEarly stopping triggered after 25 epochs.\n\nTraining complete for LR=0.0001. Total time: 17.42 seconds.\n\nSaving best model weights to meld_emotion_classifier_weighted_lr_0.0001.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=0.0001)...\nTest Accuracy: 57.05%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.33      0.31      0.32       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.25      0.02      0.04        50\n         joy       0.44      0.41      0.42       402\n     neutral       0.66      0.86      0.75      1256\n     sadness       0.34      0.10      0.16       208\n    surprise       0.52      0.39      0.45       281\n\n    accuracy                           0.57      2610\n   macro avg       0.36      0.30      0.30      2610\nweighted avg       0.52      0.57      0.53      2610\n\n\n=======================================================\n=== STARTING TRAINING RUN: LEARNING RATE = 1e-05 ===\n=======================================================\n\nBuilding model...\nDenseClassifier(\n  (network): Sequential(\n    (0): Linear(in_features=1536, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.3, inplace=False)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.3, inplace=False)\n    (6): Linear(in_features=128, out_features=7, bias=True)\n  )\n)\n\nStarting training...\nEpoch 1/40 | Train Loss: 1.8900 | Train Acc: 43.75% | Val Loss: 1.8757 | Val Acc: 42.33%\n  New best validation accuracy: 42.33%. Saving model state...\nEpoch 2/40 | Train Loss: 1.8437 | Train Acc: 47.10% | Val Loss: 1.8622 | Val Acc: 42.33%\nEpoch 3/40 | Train Loss: 1.8242 | Train Acc: 47.11% | Val Loss: 1.8564 | Val Acc: 42.33%\nEpoch 4/40 | Train Loss: 1.8237 | Train Acc: 47.15% | Val Loss: 1.8468 | Val Acc: 42.33%\nEpoch 5/40 | Train Loss: 1.8093 | Train Acc: 47.37% | Val Loss: 1.8355 | Val Acc: 42.42%\n  New best validation accuracy: 42.42%. Saving model state...\nEpoch 6/40 | Train Loss: 1.8030 | Train Acc: 47.80% | Val Loss: 1.8279 | Val Acc: 42.69%\n  New best validation accuracy: 42.69%. Saving model state...\nEpoch 7/40 | Train Loss: 1.7891 | Train Acc: 48.12% | Val Loss: 1.8179 | Val Acc: 43.68%\n  New best validation accuracy: 43.68%. Saving model state...\nEpoch 8/40 | Train Loss: 1.7799 | Train Acc: 48.67% | Val Loss: 1.8034 | Val Acc: 45.76%\n  New best validation accuracy: 45.76%. Saving model state...\nEpoch 9/40 | Train Loss: 1.7712 | Train Acc: 49.68% | Val Loss: 1.7954 | Val Acc: 46.30%\n  New best validation accuracy: 46.30%. Saving model state...\nEpoch 10/40 | Train Loss: 1.7659 | Train Acc: 50.25% | Val Loss: 1.7840 | Val Acc: 46.84%\n  New best validation accuracy: 46.84%. Saving model state...\nEpoch 11/40 | Train Loss: 1.7494 | Train Acc: 50.51% | Val Loss: 1.7770 | Val Acc: 47.56%\n  New best validation accuracy: 47.56%. Saving model state...\nEpoch 12/40 | Train Loss: 1.7361 | Train Acc: 51.22% | Val Loss: 1.7691 | Val Acc: 47.02%\nEpoch 13/40 | Train Loss: 1.7323 | Train Acc: 50.91% | Val Loss: 1.7607 | Val Acc: 47.29%\nEpoch 14/40 | Train Loss: 1.7209 | Train Acc: 51.26% | Val Loss: 1.7550 | Val Acc: 47.47%\nEpoch 15/40 | Train Loss: 1.7168 | Train Acc: 51.66% | Val Loss: 1.7494 | Val Acc: 47.20%\nEpoch 16/40 | Train Loss: 1.7085 | Train Acc: 52.16% | Val Loss: 1.7419 | Val Acc: 48.01%\n  New best validation accuracy: 48.01%. Saving model state...\nEpoch 17/40 | Train Loss: 1.7094 | Train Acc: 51.52% | Val Loss: 1.7390 | Val Acc: 48.01%\nEpoch 18/40 | Train Loss: 1.7035 | Train Acc: 52.49% | Val Loss: 1.7346 | Val Acc: 48.47%\n  New best validation accuracy: 48.47%. Saving model state...\nEpoch 19/40 | Train Loss: 1.6947 | Train Acc: 51.90% | Val Loss: 1.7340 | Val Acc: 48.74%\n  New best validation accuracy: 48.74%. Saving model state...\nEpoch 20/40 | Train Loss: 1.6895 | Train Acc: 52.56% | Val Loss: 1.7281 | Val Acc: 49.01%\n  New best validation accuracy: 49.01%. Saving model state...\nEpoch 21/40 | Train Loss: 1.6827 | Train Acc: 52.72% | Val Loss: 1.7250 | Val Acc: 48.65%\nEpoch 22/40 | Train Loss: 1.6834 | Train Acc: 52.79% | Val Loss: 1.7201 | Val Acc: 49.01%\nEpoch 23/40 | Train Loss: 1.6798 | Train Acc: 52.42% | Val Loss: 1.7194 | Val Acc: 49.10%\n  New best validation accuracy: 49.10%. Saving model state...\nEpoch 24/40 | Train Loss: 1.6733 | Train Acc: 53.06% | Val Loss: 1.7148 | Val Acc: 48.92%\nEpoch 25/40 | Train Loss: 1.6746 | Train Acc: 53.31% | Val Loss: 1.7128 | Val Acc: 49.10%\nEpoch 26/40 | Train Loss: 1.6722 | Train Acc: 53.66% | Val Loss: 1.7128 | Val Acc: 49.37%\n  New best validation accuracy: 49.37%. Saving model state...\nEpoch 27/40 | Train Loss: 1.6588 | Train Acc: 53.39% | Val Loss: 1.7097 | Val Acc: 49.10%\nEpoch 28/40 | Train Loss: 1.6590 | Train Acc: 53.21% | Val Loss: 1.7062 | Val Acc: 49.37%\nEpoch 29/40 | Train Loss: 1.6578 | Train Acc: 53.59% | Val Loss: 1.7050 | Val Acc: 49.55%\n  New best validation accuracy: 49.55%. Saving model state...\nEpoch 30/40 | Train Loss: 1.6546 | Train Acc: 53.98% | Val Loss: 1.7021 | Val Acc: 50.00%\n  New best validation accuracy: 50.00%. Saving model state...\nEpoch 31/40 | Train Loss: 1.6502 | Train Acc: 53.81% | Val Loss: 1.7005 | Val Acc: 49.46%\nEpoch 32/40 | Train Loss: 1.6470 | Train Acc: 53.68% | Val Loss: 1.6996 | Val Acc: 49.73%\nEpoch 33/40 | Train Loss: 1.6465 | Train Acc: 53.61% | Val Loss: 1.7007 | Val Acc: 49.64%\nEpoch 34/40 | Train Loss: 1.6427 | Train Acc: 54.12% | Val Loss: 1.6961 | Val Acc: 49.37%\nEpoch 35/40 | Train Loss: 1.6400 | Train Acc: 54.56% | Val Loss: 1.6937 | Val Acc: 49.37%\nEpoch 36/40 | Train Loss: 1.6359 | Train Acc: 54.57% | Val Loss: 1.6957 | Val Acc: 50.36%\n  New best validation accuracy: 50.36%. Saving model state...\nEpoch 37/40 | Train Loss: 1.6374 | Train Acc: 53.99% | Val Loss: 1.6920 | Val Acc: 49.91%\nEpoch 38/40 | Train Loss: 1.6395 | Train Acc: 54.37% | Val Loss: 1.6918 | Val Acc: 50.27%\nEpoch 39/40 | Train Loss: 1.6290 | Train Acc: 54.54% | Val Loss: 1.6887 | Val Acc: 49.64%\nEpoch 40/40 | Train Loss: 1.6280 | Train Acc: 54.49% | Val Loss: 1.6905 | Val Acc: 49.73%\n\nTraining complete for LR=1e-05. Total time: 27.42 seconds.\n\nSaving best model weights to meld_emotion_classifier_weighted_lr_1e-05.pth...\n✓ Model saved.\n\nEvaluating on Test Set (for LR=1e-05)...\nTest Accuracy: 54.48%\n\nClassification Report (Test Set):\n              precision    recall  f1-score   support\n\n       anger       0.27      0.06      0.10       345\n     disgust       0.00      0.00      0.00        68\n        fear       0.00      0.00      0.00        50\n         joy       0.37      0.44      0.40       402\n     neutral       0.63      0.89      0.74      1256\n     sadness       0.00      0.00      0.00       208\n    surprise       0.38      0.40      0.39       281\n\n    accuracy                           0.54      2610\n   macro avg       0.24      0.25      0.23      2610\nweighted avg       0.44      0.54      0.47      2610\n\n\nAll training runs finished.\n","output_type":"stream"}],"execution_count":1}]}